{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T13:57:13.782843Z","iopub.execute_input":"2023-08-10T13:57:13.783315Z","iopub.status.idle":"2023-08-10T13:57:13.789843Z","shell.execute_reply.started":"2023-08-10T13:57:13.783281Z","shell.execute_reply":"2023-08-10T13:57:13.788101Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/dataset0/data.csv')\ndata_specificity = pd.read_json('/kaggle/input/data-specificity/data-specificity.json')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:13.792102Z","iopub.execute_input":"2023-08-10T13:57:13.792457Z","iopub.status.idle":"2023-08-10T13:57:13.849364Z","shell.execute_reply.started":"2023-08-10T13:57:13.792425Z","shell.execute_reply":"2023-08-10T13:57:13.847918Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":" Criteria for defining a personal event memory by Pillemer ( 1998 ) :  \n*  (a) present a specific event that took place at a particular time and place, rather than a summary event or extended series of events.\n* (b) contain a detailed account of the rememberer's own personal circumstances at the time of the event. \n* (c) evoke sensory images or bodily sensations that contribute to the feeling of \"re-experiencing\" or \"reliving\" the event.\n* (d) link its details and images to a particular moment or moments of phenomenal experience. \n* (e) be believed to be a truthful representation of what actually transpired.","metadata":{}},{"cell_type":"markdown","source":"## 1. Specificity","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.chunk import ne_chunk\nimport spacy\n\n# Tokenization\ndef tokenize_text(text):\n    return sent_tokenize(text)\n\n# Part-of-Speech (POS) Tagging\ndef pos_tagging(text):\n    tokens = word_tokenize(text)\n    return pos_tag(tokens)\n\n\n#  Named Entity Recognition (SpaCy)\ndef named_entity_recognition_spacy(text):\n    nlp = spacy.load('en_core_web_sm')\n    doc = nlp(text)\n    named_entities = [ent.text for ent in doc.ents]\n    return named_entities\n\n# Event Extraction\ndef extract_events(text):\n    tokens = word_tokenize(text)\n    tagged = pos_tag(tokens)\n    events = []\n    current_event = []\n    for tag in tagged:\n        if tag[1].startswith('VB'):\n            current_event.append(tag[0])\n        elif current_event:\n            events.append(' '.join(current_event))\n            current_event = []\n    if current_event:\n        events.append(' '.join(current_event))\n    return events\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:13.851398Z","iopub.execute_input":"2023-08-10T13:57:13.852286Z","iopub.status.idle":"2023-08-10T13:57:29.570169Z","shell.execute_reply.started":"2023-08-10T13:57:13.852249Z","shell.execute_reply":"2023-08-10T13:57:29.569162Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"print(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:29.571735Z","iopub.execute_input":"2023-08-10T13:57:29.573508Z","iopub.status.idle":"2023-08-10T13:57:29.582189Z","shell.execute_reply.started":"2023-08-10T13:57:29.573458Z","shell.execute_reply":"2023-08-10T13:57:29.580114Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"the loss of my father will forever leave an indelible mark on my heart it also provided me with an unwavering strength. It shaped me into a more resilient and compassionate person capable of facing adversity with newfound determination. I carry my father's memory with me drawing inspiration from his life and the lessons he imparted. Through this turning point I have learned that strength can emerge from even the darkest moments and I am committed to living a life that honors his legacy.\n","output_type":"stream"}]},{"cell_type":"code","source":"def specificity_spacy(story):\n    sentences = tokenize_text(story)\n    tagged_sentences = [pos_tagging(sentence) for sentence in sentences]\n    named_entities = [named_entity_recognition_spacy(sentence) for sentence in sentences]\n    print( \"named entities\", named_entities)\n    events = [extract_events(sentence) for sentence in sentences]\n    print(\"events\", events)\n    total_named_entities = sum(len(ne_list) for ne_list in named_entities)\n    total_events = sum(len(event_list) for event_list in events)\n    total_sentences = len(sentences)\n    \n    threshold = total_sentences // 5\n    \n    # Check if total_named_entities and total_events are greater than the threshold\n    is_specific_story = ( total_named_entities > threshold ) & ( total_events > threshold )\n    \n    return is_specific_story","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:29.585545Z","iopub.execute_input":"2023-08-10T13:57:29.585901Z","iopub.status.idle":"2023-08-10T13:57:29.603538Z","shell.execute_reply.started":"2023-08-10T13:57:29.585872Z","shell.execute_reply":"2023-08-10T13:57:29.602527Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Testing the specifity_ne_spacy function :","metadata":{}},{"cell_type":"code","source":"\n\n# Example usage\nstory_text = \"Once upon a time, in a faraway land, there lived a brave knight named Sir Lancelot...\"\nis_specific_story = specificity_spacy(story_text)\nprint(\"Is the story specific?\", is_specific_story)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:29.604987Z","iopub.execute_input":"2023-08-10T13:57:29.605437Z","iopub.status.idle":"2023-08-10T13:57:31.292413Z","shell.execute_reply.started":"2023-08-10T13:57:29.605398Z","shell.execute_reply":"2023-08-10T13:57:31.291231Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"named entities [['Lancelot']]\nevents [['lived', 'named']]\nIs the story specific? True\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Example usage\nstory_text = 'The annual science fair showcased impressive projects from young innovators. Students presented their research findings on various topics. A robot that can solve complex puzzles was a highlight of the event. Researchers discussed cutting-edge advancements in artificial intelligence. The fair concluded with an awards ceremony honoring the top projects.'\nis_specific_story = specificity_spacy(story_text)\nprint(\"Is the story specific?\", is_specific_story)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:31.294492Z","iopub.execute_input":"2023-08-10T13:57:31.294948Z","iopub.status.idle":"2023-08-10T13:57:37.499430Z","shell.execute_reply.started":"2023-08-10T13:57:31.294908Z","shell.execute_reply":"2023-08-10T13:57:37.498129Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"named entities [[], [], [], [], []]\nevents [['showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nIs the story specific? False\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Example usage\nstory_text = 'The annual science called Gitex fair showcased impressive projects from young innovators. Students presented their research findings on various topics. A robot that can solve complex puzzles was a highlight of the event. Researchers discussed cutting-edge advancements in artificial intelligence. The fair concluded with an awards ceremony honoring the top projects.'\nis_specific_story = specificity_spacy(story_text)\nprint(\"Is the story specific?\", is_specific_story)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:37.500835Z","iopub.execute_input":"2023-08-10T13:57:37.501189Z","iopub.status.idle":"2023-08-10T13:57:44.243356Z","shell.execute_reply.started":"2023-08-10T13:57:37.501159Z","shell.execute_reply":"2023-08-10T13:57:44.242158Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"named entities [['Gitex'], [], [], [], []]\nevents [['called', 'showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nIs the story specific? False\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_specificity_dataframe(data_frame):\n    correct_predictions = 0\n    total_stories = len(data_frame)\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['is_specific']\n        \n        predicted_label = specificity_spacy(story)\n        \n        # Convert boolean to string\n        predicted_label_str = \"yes\" if predicted_label else \"no\"\n        \n        if predicted_label_str == ground_truth_label:\n            correct_predictions += 1\n\n    accuracy = correct_predictions / total_stories\n\n    return accuracy\n\naccuracy = evaluate_specificity_dataframe(data_specificity)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T14:17:43.210038Z","iopub.execute_input":"2023-08-10T14:17:43.210527Z","iopub.status.idle":"2023-08-10T14:18:12.453589Z","shell.execute_reply.started":"2023-08-10T14:17:43.210493Z","shell.execute_reply":"2023-08-10T14:18:12.452377Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"named entities [['Gitex'], [], [], [], []]\nevents [['called', 'showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nnamed entities [[], [], [], [], []]\nevents [['set'], ['turned'], ['flew'], ['descended'], ['was captivating']]\nnamed entities [[], [], [], [], []]\nevents [['walked'], ['honked', 'shouted'], ['took'], ['gave'], ['cheered']]\nnamed entities [[], [], [], []]\nevents [['embarked'], ['sought', 'save'], ['encountered', 'forged'], ['were']]\nnamed entities [['midnight'], ['Ali'], [], [], []]\nevents [['struck'], ['crossed'], ['walked'], ['whispered'], ['emerged']]\nAccuracy: 0.60\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_precision(data_frame):\n    true_positives = 0\n    false_positives = 0\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['is_specific']\n\n        predicted_label = specificity_spacy(story)\n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif predicted_label and ground_truth_label == \"no\":\n            false_positives += 1\n\n    precision = true_positives / (true_positives + false_positives)\n    return precision\n\nprecision = evaluate_precision(data_specificity)\nprint(f\"Precision: {precision:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T14:23:28.529801Z","iopub.execute_input":"2023-08-10T14:23:28.530304Z","iopub.status.idle":"2023-08-10T14:23:57.978551Z","shell.execute_reply.started":"2023-08-10T14:23:28.530268Z","shell.execute_reply":"2023-08-10T14:23:57.977066Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"named entities [['Gitex'], [], [], [], []]\nevents [['called', 'showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nnamed entities [[], [], [], [], []]\nevents [['set'], ['turned'], ['flew'], ['descended'], ['was captivating']]\nnamed entities [[], [], [], [], []]\nevents [['walked'], ['honked', 'shouted'], ['took'], ['gave'], ['cheered']]\nnamed entities [[], [], [], []]\nevents [['embarked'], ['sought', 'save'], ['encountered', 'forged'], ['were']]\nnamed entities [['midnight'], ['Ali'], [], [], []]\nevents [['struck'], ['crossed'], ['walked'], ['whispered'], ['emerged']]\nPrecision: 1.00\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_recall(data_frame):\n    true_positives = 0\n    false_negatives = 0\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['is_specific']\n\n        predicted_label = specificity_spacy(story)\n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif not predicted_label and ground_truth_label == \"yes\":\n            false_negatives += 1\n\n    recall = true_positives / (true_positives + false_negatives)\n    return recall\n\nrecall = evaluate_recall(data_specificity)\nprint(f\"Recall: {recall:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T14:26:58.257171Z","iopub.execute_input":"2023-08-10T14:26:58.257553Z","iopub.status.idle":"2023-08-10T14:27:29.097149Z","shell.execute_reply.started":"2023-08-10T14:26:58.257524Z","shell.execute_reply":"2023-08-10T14:27:29.095606Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"named entities [['Gitex'], [], [], [], []]\nevents [['called', 'showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nnamed entities [[], [], [], [], []]\nevents [['set'], ['turned'], ['flew'], ['descended'], ['was captivating']]\nnamed entities [[], [], [], [], []]\nevents [['walked'], ['honked', 'shouted'], ['took'], ['gave'], ['cheered']]\nnamed entities [[], [], [], []]\nevents [['embarked'], ['sought', 'save'], ['encountered', 'forged'], ['were']]\nnamed entities [['midnight'], ['Ali'], [], [], []]\nevents [['struck'], ['crossed'], ['walked'], ['whispered'], ['emerged']]\nRecall: 0.33\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here's what recall reflects:\n\nCompleteness: Recall indicates how well your model is capturing all instances of the positive class (in your case, the specific stories). A higher recall means that your model is successfully identifying most of the specific stories present in the dataset.\n\nMissed Positive Cases: A low recall value suggests that your model is missing a significant portion of the positive cases. This could mean that the model is not sensitive enough to detect the specific stories, leading to false negatives.\n\nTrade-off with Precision: Recall is often in conflict with precision. A high recall could lead to more false positives (cases incorrectly classified as positive), as the model may be more inclusive in classifying instances as positive. Balancing recall and precision is important depending on your use case.","metadata":{}},{"cell_type":"markdown","source":"# 2.Personal Context ","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom gensim import corpora, models\n\ndef evaluate_personal_context(text):\n    # Tokenize text into sentences\n    sentences = nltk.sent_tokenize(text)\n\n    # Sentiment Analysis\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = [sia.polarity_scores(sentence)[\"compound\"] for sentence in sentences]\n\n    # Topic Modeling\n    tokenized_sentences = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n    dictionary = corpora.Dictionary(tokenized_sentences)\n    corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_sentences]\n    lda_model = models.LdaModel(corpus, num_topics=3, id2word=dictionary)\n\n    # Extract most significant topics\n    topics = [lda_model.get_document_topics(doc) for doc in corpus]\n    most_significant_topics = [max(topic, key=lambda x: x[1]) for topic in topics]\n\n    # Get actual topics\n    actual_topics = [lda_model.print_topic(topic[0]) for topic in most_significant_topics]\n\n    # Return sentiment scores and actual topics\n    return sentiment_scores, actual_topics\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.021381Z","iopub.status.idle":"2023-08-10T13:57:45.022032Z","shell.execute_reply.started":"2023-08-10T13:57:45.021799Z","shell.execute_reply":"2023-08-10T13:57:45.021822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the context of topic modeling with LDA, the weights assigned to each word in a topic represent the importance or prevalence of that word within the topic. In the output you provided\n\nUnderstanding the significance of individual words and their weights within a topic can help provide insights into the key themes and subjects present in the text.","metadata":{}},{"cell_type":"code","source":"def test_personal_context(text):\n    sentiment_scores, actual_topics = evaluate_personal_context(text)\n    print(\"Sentiment Scores:\", sentiment_scores)\n    print()\n    print(\"Actual Topics:\")\n    for topic in actual_topics:\n        print(topic)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.024041Z","iopub.status.idle":"2023-08-10T13:57:45.024581Z","shell.execute_reply.started":"2023-08-10T13:57:45.024356Z","shell.execute_reply":"2023-08-10T13:57:45.024377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_personal_context(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.026610Z","iopub.status.idle":"2023-08-10T13:57:45.027019Z","shell.execute_reply.started":"2023-08-10T13:57:45.026827Z","shell.execute_reply":"2023-08-10T13:57:45.026845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_personal_context(\"i lost my best friend and im so happy\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.028517Z","iopub.status.idle":"2023-08-10T13:57:45.028911Z","shell.execute_reply.started":"2023-08-10T13:57:45.028719Z","shell.execute_reply":"2023-08-10T13:57:45.028737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the word \"my\" has the highest weight of 0.102 for the extracted topic.\n\nA high weight for the word \"my\" suggests that it is a significant term within the topic identified by the LDA model. This means that the word \"my\" occurs frequently and carries substantial importance within the text when discussing the particular topic associated with that topic index.\n\nIn this case, it indicates that personal ownership or possession, likely related to the topic of loss and enduring emotional impact, plays a prominent role in the text. The word \"my\" may be indicating a personal connection or the speaker's individual perspective in relation to the topic being discussed.","metadata":{}},{"cell_type":"markdown","source":"## 3.Sensory details ","metadata":{}},{"cell_type":"code","source":"import nltk\n\ndef analyze_sensory_details(text):\n    sentences = nltk.sent_tokenize(text)\n\n    sensory_keywords = {\n        'sight': ['see', 'look', 'watch'],\n        'sound': ['hear', 'listen', 'sound'],\n        'smell': ['smell', 'scent', 'aroma'],\n        'taste': ['taste', 'flavor'],\n        'touch': ['feel', 'touch', 'texture']\n    }\n\n    sensory_details = []\n    for sentence in sentences:\n        lower_sentence = sentence.lower()\n        for sense, keywords in sensory_keywords.items():\n            for keyword in keywords:\n                if keyword in lower_sentence:\n                    sensory_details.append({'sense': sense, 'sentence': sentence})\n                    break\n\n    return sensory_details\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.030693Z","iopub.status.idle":"2023-08-10T13:57:45.031103Z","shell.execute_reply.started":"2023-08-10T13:57:45.030891Z","shell.execute_reply":"2023-08-10T13:57:45.030909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_sensory_details(text):\n    sensory_details = analyze_sensory_details(text)\n    print(\"Sensory Details:\")\n    for detail in sensory_details:\n        print(f\"{detail['sense']}: {detail['sentence']}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.032877Z","iopub.status.idle":"2023-08-10T13:57:45.033304Z","shell.execute_reply.started":"2023-08-10T13:57:45.033083Z","shell.execute_reply":"2023-08-10T13:57:45.033101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sensory_details(data.iloc[2]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.034486Z","iopub.status.idle":"2023-08-10T13:57:45.034862Z","shell.execute_reply.started":"2023-08-10T13:57:45.034678Z","shell.execute_reply":"2023-08-10T13:57:45.034696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.Phenominal experience ","metadata":{}},{"cell_type":"markdown","source":"using emotional analysis ","metadata":{}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\n\ndef analyze_emotional_tone(text):\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = sia.polarity_scores(text)\n    return sentiment_scores\n\nspeech = \"The loss of my father will forever leave an indelible mark on my heart. But im so happy that he died\"\n\nemotion_scores = analyze_emotional_tone(speech)\nprint(\"Emotion Scores:\", emotion_scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.036351Z","iopub.status.idle":"2023-08-10T13:57:45.036927Z","shell.execute_reply.started":"2023-08-10T13:57:45.036730Z","shell.execute_reply":"2023-08-10T13:57:45.036748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Truthfulness","metadata":{}},{"cell_type":"markdown","source":"## Metrics ","metadata":{"execution":{"iopub.status.busy":"2023-08-09T14:10:16.442941Z","iopub.execute_input":"2023-08-09T14:10:16.444197Z","iopub.status.idle":"2023-08-09T14:10:16.478844Z","shell.execute_reply.started":"2023-08-09T14:10:16.444144Z","shell.execute_reply":"2023-08-09T14:10:16.477636Z"}}},{"cell_type":"markdown","source":"- Accuracy: This metric measures the ratio of correctly predicted instances to the total instances in the dataset. It's a common metric for overall performance.\n- Precision: Precision calculates the ratio of true positive predictions to the total predicted positive instances. It measures how accurate the positive predictions are.\n- Recall: Also known as sensitivity or true positive rate, recall measures the ratio of true positive predictions to the total actual positive instances. It gauges how well the model captures all the positive instances.","metadata":{}},{"cell_type":"markdown","source":"### Specificity","metadata":{}},{"cell_type":"code","source":"def is_specific(story):\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.038269Z","iopub.status.idle":"2023-08-10T13:57:45.038675Z","shell.execute_reply.started":"2023-08-10T13:57:45.038490Z","shell.execute_reply":"2023-08-10T13:57:45.038508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def specificity_ne1(story, ground_truth_named_entities, ground_truth_events):\n    sentences = tokenize_text(story)\n    \n    tagged_sentences = [pos_tagging(sentence) for sentence in sentences]\n    named_entities = [named_entity_recognition(sentence) for sentence in sentences]\n    events = [extract_events(sentence) for sentence in sentences]\n    \n    specific_named_entities = []\n    specific_events = []\n\n    for ne_list, event_list in zip(named_entities, events):\n        for named_entity in ne_list:\n            if is_specific(named_entity):\n                specific_named_entities.append(named_entity)\n\n        for event in event_list:\n            if is_specific(event):\n                specific_events.append(event)\n\n    # Calculate metrics\n    true_positive_named_entities = len(set(specific_named_entities) & set(ground_truth_named_entities))\n    false_positive_named_entities = len(set(specific_named_entities) - set(ground_truth_named_entities))\n    false_negative_named_entities = len(set(ground_truth_named_entities) - set(specific_named_entities))\n    \n    true_positive_events = len(set(specific_events) & set(ground_truth_events))\n    false_positive_events = len(set(specific_events) - set(ground_truth_events))\n    false_negative_events = len(set(ground_truth_events) - set(specific_events))\n    \n    accuracy = (true_positive_named_entities + true_positive_events) / (len(ground_truth_named_entities) + len(ground_truth_events))\n    \n    precision_named_entities = true_positive_named_entities / (true_positive_named_entities + false_positive_named_entities)\n    recall_named_entities = true_positive_named_entities / (true_positive_named_entities + false_negative_named_entities)\n    \n    precision_events = true_positive_events / (true_positive_events + false_positive_events)\n    recall_events = true_positive_events / (true_positive_events + false_negative_events)\n\n    return {\n        'accuracy': accuracy,\n        'precision_named_entities': precision_named_entities,\n        'recall_named_entities': recall_named_entities,\n        'precision_events': precision_events,\n        'recall_events': recall_events\n    }\n\n# Example usage\nstory_text = \"Once upon a time, in a faraway land, there lived a brave knight named Sir Lancelot...\"\nground_truth_named_entities = [\"Sir Lancelot\"]\nground_truth_events = [\"lived\"]\nmetrics = specificity_ne1(story_text, ground_truth_named_entities, ground_truth_events)\nprint(metrics)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T13:57:45.039737Z","iopub.status.idle":"2023-08-10T13:57:45.040107Z","shell.execute_reply.started":"2023-08-10T13:57:45.039915Z","shell.execute_reply":"2023-08-10T13:57:45.039932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}