{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-08T19:06:07.892510Z","iopub.execute_input":"2023-08-08T19:06:07.892954Z","iopub.status.idle":"2023-08-08T19:06:07.965850Z","shell.execute_reply.started":"2023-08-08T19:06:07.892921Z","shell.execute_reply":"2023-08-08T19:06:07.964517Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/dataset0/data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:08:53.395616Z","iopub.execute_input":"2023-08-08T19:08:53.396014Z","iopub.status.idle":"2023-08-08T19:08:53.419909Z","shell.execute_reply.started":"2023-08-08T19:08:53.395986Z","shell.execute_reply":"2023-08-08T19:08:53.419031Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":" Criteria for defining a personal event memory by Pillemer ( 1998 ) :  \n*  (a) present a specific event that took place at a particular time and place, rather than a summary event or extended series of events.\n* (b) contain a detailed account of the rememberer's own personal circumstances at the time of the event. \n* (c) evoke sensory images or bodily sensations that contribute to the feeling of \"re-experiencing\" or \"reliving\" the event.\n* (d) link its details and images to a particular moment or moments of phenomenal experience. \n* (e) be believed to be a truthful representation of what actually transpired.","metadata":{}},{"cell_type":"markdown","source":"## 1. Specificity","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.chunk import ne_chunk\n\n# Tokenization\ndef tokenize_text(text):\n    return sent_tokenize(text)\n\n# Part-of-Speech (POS) Tagging\ndef pos_tagging(text):\n    tokens = word_tokenize(text)\n    return pos_tag(tokens)\n\n\n#  Named Entity Recognition (NER)\ndef named_entity_recognition(text):\n    tokens = word_tokenize(text)\n    tagged = pos_tag(tokens)\n    ne_tree = ne_chunk(tagged)\n    named_entities = []\n    for chunk in ne_tree:\n        if hasattr(chunk, 'label') and chunk.label() == 'NE':\n            named_entities.append(' '.join(c[0] for c in chunk))\n    return named_entities\n\n# Event Extraction\ndef extract_events(text):\n    tokens = word_tokenize(text)\n    tagged = pos_tag(tokens)\n    events = []\n    current_event = []\n    for tag in tagged:\n        if tag[1].startswith('VB'):\n            current_event.append(tag[0])\n        elif current_event:\n            events.append(' '.join(current_event))\n            current_event = []\n    if current_event:\n        events.append(' '.join(current_event))\n    return events\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:06:13.848057Z","iopub.execute_input":"2023-08-08T19:06:13.848515Z","iopub.status.idle":"2023-08-08T19:06:13.861300Z","shell.execute_reply.started":"2023-08-08T19:06:13.848479Z","shell.execute_reply":"2023-08-08T19:06:13.860240Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Testing function for specificity","metadata":{}},{"cell_type":"code","source":"print(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:06:34.519877Z","iopub.execute_input":"2023-08-08T19:06:34.520386Z","iopub.status.idle":"2023-08-08T19:06:34.565484Z","shell.execute_reply.started":"2023-08-08T19:06:34.520353Z","shell.execute_reply":"2023-08-08T19:06:34.563383Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStory\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"def specificity_ne(story):\n    sentences = tokenize_text(story)\n    print('Sentences:', sentences)\n    print()\n    tagged_sentences = [pos_tagging(sentence) for sentence in sentences]\n    print('Tagged Sentences:', tagged_sentences)\n    print()\n    named_entities = [named_entity_recognition(sentence) for sentence in sentences]\n    print('Named Entities:', named_entities)\n    print()\n    events = [extract_events(sentence) for sentence in sentences]\n    print('Events:', events)\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:58:22.342381Z","iopub.execute_input":"2023-08-08T15:58:22.342898Z","iopub.status.idle":"2023-08-08T15:58:22.351358Z","shell.execute_reply.started":"2023-08-08T15:58:22.342861Z","shell.execute_reply":"2023-08-08T15:58:22.350013Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Testing","metadata":{}},{"cell_type":"code","source":"specificity_ne(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:58:23.993512Z","iopub.execute_input":"2023-08-08T15:58:23.993906Z","iopub.status.idle":"2023-08-08T15:58:24.054602Z","shell.execute_reply.started":"2023-08-08T15:58:23.993877Z","shell.execute_reply":"2023-08-08T15:58:24.053212Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Sentences: ['the loss of my father will forever leave an indelible mark on my heart it also provided me with an unwavering strength it shaped me into a more resilient and compassionate person capable of facing adversity with newfound determination i carry my fathers memory with me drawing inspiration from his life and the lessons he imparted through this turning point i have learned that strength can emerge from even the darkest moments and i am committed to living a life that honors his legacy']\n\nTagged Sentences: [[('the', 'DT'), ('loss', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('father', 'NN'), ('will', 'MD'), ('forever', 'VB'), ('leave', 'VB'), ('an', 'DT'), ('indelible', 'JJ'), ('mark', 'NN'), ('on', 'IN'), ('my', 'PRP$'), ('heart', 'NN'), ('it', 'PRP'), ('also', 'RB'), ('provided', 'VBD'), ('me', 'PRP'), ('with', 'IN'), ('an', 'DT'), ('unwavering', 'JJ'), ('strength', 'NN'), ('it', 'PRP'), ('shaped', 'VBD'), ('me', 'PRP'), ('into', 'IN'), ('a', 'DT'), ('more', 'RBR'), ('resilient', 'JJ'), ('and', 'CC'), ('compassionate', 'JJ'), ('person', 'NN'), ('capable', 'JJ'), ('of', 'IN'), ('facing', 'VBG'), ('adversity', 'NN'), ('with', 'IN'), ('newfound', 'JJ'), ('determination', 'NN'), ('i', 'NN'), ('carry', 'VBP'), ('my', 'PRP$'), ('fathers', 'NNS'), ('memory', 'NN'), ('with', 'IN'), ('me', 'PRP'), ('drawing', 'VBG'), ('inspiration', 'NN'), ('from', 'IN'), ('his', 'PRP$'), ('life', 'NN'), ('and', 'CC'), ('the', 'DT'), ('lessons', 'NNS'), ('he', 'PRP'), ('imparted', 'VBD'), ('through', 'IN'), ('this', 'DT'), ('turning', 'JJ'), ('point', 'NN'), ('i', 'NN'), ('have', 'VBP'), ('learned', 'VBN'), ('that', 'IN'), ('strength', 'NN'), ('can', 'MD'), ('emerge', 'VB'), ('from', 'IN'), ('even', 'RB'), ('the', 'DT'), ('darkest', 'JJS'), ('moments', 'NNS'), ('and', 'CC'), ('i', 'VB'), ('am', 'VBP'), ('committed', 'VBN'), ('to', 'TO'), ('living', 'VBG'), ('a', 'DT'), ('life', 'NN'), ('that', 'WDT'), ('honors', 'VBZ'), ('his', 'PRP$'), ('legacy', 'NN')]]\n\nNamed Entities: [[]]\n\nEvents: [['forever leave', 'provided', 'shaped', 'facing', 'carry', 'drawing', 'imparted', 'have learned', 'emerge', 'i am committed', 'living', 'honors']]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The model is not able to capture named entities. Let's try with another example  ","metadata":{}},{"cell_type":"code","source":"specificity_ne(data.iloc[1]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T15:58:43.156699Z","iopub.execute_input":"2023-08-08T15:58:43.157147Z","iopub.status.idle":"2023-08-08T15:58:43.204644Z","shell.execute_reply.started":"2023-08-08T15:58:43.157112Z","shell.execute_reply":"2023-08-08T15:58:43.203626Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Sentences: ['i adopted a cat 7 months ago i wasnt planning it and it was like a dream to me and one day my mom entered the house with a kitten in her hands and it was the happiest day of my life i couldnt believe it and since then lili  my cat became the only being that i really love from the bottom of my heart']\n\nTagged Sentences: [[('i', 'NN'), ('adopted', 'VBD'), ('a', 'DT'), ('cat', 'JJ'), ('7', 'CD'), ('months', 'NNS'), ('ago', 'IN'), ('i', 'JJ'), ('wasnt', 'VBP'), ('planning', 'VBG'), ('it', 'PRP'), ('and', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('like', 'IN'), ('a', 'DT'), ('dream', 'NN'), ('to', 'TO'), ('me', 'PRP'), ('and', 'CC'), ('one', 'CD'), ('day', 'NN'), ('my', 'PRP$'), ('mom', 'NN'), ('entered', 'VBD'), ('the', 'DT'), ('house', 'NN'), ('with', 'IN'), ('a', 'DT'), ('kitten', 'NN'), ('in', 'IN'), ('her', 'PRP$'), ('hands', 'NNS'), ('and', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('happiest', 'JJS'), ('day', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('i', 'NN'), ('couldnt', 'VBP'), ('believe', 'VBP'), ('it', 'PRP'), ('and', 'CC'), ('since', 'IN'), ('then', 'RB'), ('lili', 'VB'), ('my', 'PRP$'), ('cat', 'NN'), ('became', 'VBD'), ('the', 'DT'), ('only', 'JJ'), ('being', 'VBG'), ('that', 'IN'), ('i', 'NN'), ('really', 'RB'), ('love', 'VB'), ('from', 'IN'), ('the', 'DT'), ('bottom', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('heart', 'NN')]]\n\nNamed Entities: [[]]\n\nEvents: [['adopted', 'wasnt planning', 'was', 'entered', 'was', 'couldnt believe', 'lili', 'became', 'being', 'love']]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":" NE was not able to capture any named entity. Let's try with other python library. \n Let's start with SpaCy","metadata":{}},{"cell_type":"code","source":"import spacy\n\ndef named_entity_recognition_spacy(text):\n    nlp = spacy.load('en_core_web_sm')\n    doc = nlp(text)\n    named_entities = [ent.text for ent in doc.ents]\n    return named_entities\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T16:00:14.519499Z","iopub.execute_input":"2023-08-08T16:00:14.519965Z","iopub.status.idle":"2023-08-08T16:00:14.526543Z","shell.execute_reply.started":"2023-08-08T16:00:14.519933Z","shell.execute_reply":"2023-08-08T16:00:14.525329Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"named_entities = [named_entity_recognition_spacy(sentence) for sentence in sentences]\nprint('Named Entities:', named_entities)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T16:00:32.325498Z","iopub.execute_input":"2023-08-08T16:00:32.325981Z","iopub.status.idle":"2023-08-08T16:00:33.852308Z","shell.execute_reply.started":"2023-08-08T16:00:32.325942Z","shell.execute_reply":"2023-08-08T16:00:33.851057Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Named Entities: [['7 months ago']]\n","output_type":"stream"}]},{"cell_type":"code","source":"def specificity_ne_spacy(story):\n    sentences = tokenize_text(story)\n    print('Sentences:', sentences)\n    tagged_sentences = [pos_tagging(sentence) for sentence in sentences]\n    print('Tagged Sentences:', tagged_sentences)\n    named_entities = [named_entity_recognition_spacy(sentence) for sentence in sentences]\n    print('Named Entities:', named_entities)\n    events = [extract_events(sentence) for sentence in sentences]\n    print('Events:', events)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T16:02:00.585523Z","iopub.execute_input":"2023-08-08T16:02:00.586062Z","iopub.status.idle":"2023-08-08T16:02:00.593955Z","shell.execute_reply.started":"2023-08-08T16:02:00.586025Z","shell.execute_reply":"2023-08-08T16:02:00.592723Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Testing the specifity_ne_spacy function :","metadata":{}},{"cell_type":"code","source":"specificity_ne_spacy(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T16:03:57.777400Z","iopub.execute_input":"2023-08-08T16:03:57.777852Z","iopub.status.idle":"2023-08-08T16:03:59.069495Z","shell.execute_reply.started":"2023-08-08T16:03:57.777816Z","shell.execute_reply":"2023-08-08T16:03:59.068170Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Sentences: ['the loss of my father will forever leave an indelible mark on my heart it also provided me with an unwavering strength it shaped me into a more resilient and compassionate person capable of facing adversity with newfound determination i carry my fathers memory with me drawing inspiration from his life and the lessons he imparted through this turning point i have learned that strength can emerge from even the darkest moments and i am committed to living a life that honors his legacy']\nTagged Sentences: [[('the', 'DT'), ('loss', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('father', 'NN'), ('will', 'MD'), ('forever', 'VB'), ('leave', 'VB'), ('an', 'DT'), ('indelible', 'JJ'), ('mark', 'NN'), ('on', 'IN'), ('my', 'PRP$'), ('heart', 'NN'), ('it', 'PRP'), ('also', 'RB'), ('provided', 'VBD'), ('me', 'PRP'), ('with', 'IN'), ('an', 'DT'), ('unwavering', 'JJ'), ('strength', 'NN'), ('it', 'PRP'), ('shaped', 'VBD'), ('me', 'PRP'), ('into', 'IN'), ('a', 'DT'), ('more', 'RBR'), ('resilient', 'JJ'), ('and', 'CC'), ('compassionate', 'JJ'), ('person', 'NN'), ('capable', 'JJ'), ('of', 'IN'), ('facing', 'VBG'), ('adversity', 'NN'), ('with', 'IN'), ('newfound', 'JJ'), ('determination', 'NN'), ('i', 'NN'), ('carry', 'VBP'), ('my', 'PRP$'), ('fathers', 'NNS'), ('memory', 'NN'), ('with', 'IN'), ('me', 'PRP'), ('drawing', 'VBG'), ('inspiration', 'NN'), ('from', 'IN'), ('his', 'PRP$'), ('life', 'NN'), ('and', 'CC'), ('the', 'DT'), ('lessons', 'NNS'), ('he', 'PRP'), ('imparted', 'VBD'), ('through', 'IN'), ('this', 'DT'), ('turning', 'JJ'), ('point', 'NN'), ('i', 'NN'), ('have', 'VBP'), ('learned', 'VBN'), ('that', 'IN'), ('strength', 'NN'), ('can', 'MD'), ('emerge', 'VB'), ('from', 'IN'), ('even', 'RB'), ('the', 'DT'), ('darkest', 'JJS'), ('moments', 'NNS'), ('and', 'CC'), ('i', 'VB'), ('am', 'VBP'), ('committed', 'VBN'), ('to', 'TO'), ('living', 'VBG'), ('a', 'DT'), ('life', 'NN'), ('that', 'WDT'), ('honors', 'VBZ'), ('his', 'PRP$'), ('legacy', 'NN')]]\nNamed Entities: [[]]\nEvents: [['forever leave', 'provided', 'shaped', 'facing', 'carry', 'drawing', 'imparted', 'have learned', 'emerge', 'i am committed', 'living', 'honors']]\n","output_type":"stream"}]},{"cell_type":"code","source":"specificity_ne_spacy(data.iloc[1]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T16:04:17.415533Z","iopub.execute_input":"2023-08-08T16:04:17.416076Z","iopub.status.idle":"2023-08-08T16:04:18.665799Z","shell.execute_reply.started":"2023-08-08T16:04:17.416021Z","shell.execute_reply":"2023-08-08T16:04:18.664556Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Sentences: ['i adopted a cat 7 months ago i wasnt planning it and it was like a dream to me and one day my mom entered the house with a kitten in her hands and it was the happiest day of my life i couldnt believe it and since then lili  my cat became the only being that i really love from the bottom of my heart']\nTagged Sentences: [[('i', 'NN'), ('adopted', 'VBD'), ('a', 'DT'), ('cat', 'JJ'), ('7', 'CD'), ('months', 'NNS'), ('ago', 'IN'), ('i', 'JJ'), ('wasnt', 'VBP'), ('planning', 'VBG'), ('it', 'PRP'), ('and', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('like', 'IN'), ('a', 'DT'), ('dream', 'NN'), ('to', 'TO'), ('me', 'PRP'), ('and', 'CC'), ('one', 'CD'), ('day', 'NN'), ('my', 'PRP$'), ('mom', 'NN'), ('entered', 'VBD'), ('the', 'DT'), ('house', 'NN'), ('with', 'IN'), ('a', 'DT'), ('kitten', 'NN'), ('in', 'IN'), ('her', 'PRP$'), ('hands', 'NNS'), ('and', 'CC'), ('it', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('happiest', 'JJS'), ('day', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('i', 'NN'), ('couldnt', 'VBP'), ('believe', 'VBP'), ('it', 'PRP'), ('and', 'CC'), ('since', 'IN'), ('then', 'RB'), ('lili', 'VB'), ('my', 'PRP$'), ('cat', 'NN'), ('became', 'VBD'), ('the', 'DT'), ('only', 'JJ'), ('being', 'VBG'), ('that', 'IN'), ('i', 'NN'), ('really', 'RB'), ('love', 'VB'), ('from', 'IN'), ('the', 'DT'), ('bottom', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('heart', 'NN')]]\nNamed Entities: [['7 months ago']]\nEvents: [['adopted', 'wasnt planning', 'was', 'entered', 'was', 'couldnt believe', 'lili', 'became', 'being', 'love']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2.Personal Context ","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom gensim import corpora, models\n\ndef evaluate_personal_context(text):\n    # Tokenize text into sentences\n    sentences = nltk.sent_tokenize(text)\n\n    # Sentiment Analysis\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = [sia.polarity_scores(sentence)[\"compound\"] for sentence in sentences]\n\n    # Topic Modeling\n    tokenized_sentences = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n    dictionary = corpora.Dictionary(tokenized_sentences)\n    corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_sentences]\n    lda_model = models.LdaModel(corpus, num_topics=3, id2word=dictionary)\n\n    # Extract most significant topics\n    topics = [lda_model.get_document_topics(doc) for doc in corpus]\n    most_significant_topics = [max(topic, key=lambda x: x[1]) for topic in topics]\n\n    # Get actual topics\n    actual_topics = [lda_model.print_topic(topic[0]) for topic in most_significant_topics]\n\n    # Return sentiment scores and actual topics\n    return sentiment_scores, actual_topics\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:09:13.281200Z","iopub.execute_input":"2023-08-08T19:09:13.281644Z","iopub.status.idle":"2023-08-08T19:09:13.291582Z","shell.execute_reply.started":"2023-08-08T19:09:13.281608Z","shell.execute_reply":"2023-08-08T19:09:13.290577Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"In the context of topic modeling with LDA, the weights assigned to each word in a topic represent the importance or prevalence of that word within the topic. In the output you provided\n\nUnderstanding the significance of individual words and their weights within a topic can help provide insights into the key themes and subjects present in the text.","metadata":{}},{"cell_type":"code","source":"def test_personal_context(text):\n    sentiment_scores, actual_topics = evaluate_personal_context(text)\n    print(\"Sentiment Scores:\", sentiment_scores)\n    print()\n    print(\"Actual Topics:\")\n    for topic in actual_topics:\n        print(topic)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:09:15.789428Z","iopub.execute_input":"2023-08-08T19:09:15.789845Z","iopub.status.idle":"2023-08-08T19:09:15.798315Z","shell.execute_reply.started":"2023-08-08T19:09:15.789813Z","shell.execute_reply":"2023-08-08T19:09:15.796968Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_personal_context(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:09:19.225268Z","iopub.execute_input":"2023-08-08T19:09:19.225658Z","iopub.status.idle":"2023-08-08T19:09:19.268092Z","shell.execute_reply.started":"2023-08-08T19:09:19.225627Z","shell.execute_reply":"2023-08-08T19:09:19.266953Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Sentiment Scores: [0.1779, 0.7152, 0.5267, 0.6597]\n\nActual Topics:\n0.039*\"my\" + 0.033*\"an\" + 0.028*\"the\" + 0.028*\".\" + 0.027*\"strength\" + 0.026*\"it\" + 0.025*\"of\" + 0.025*\"with\" + 0.024*\"me\" + 0.023*\"will\"\n0.038*\"and\" + 0.036*\".\" + 0.035*\"i\" + 0.032*\"with\" + 0.030*\"me\" + 0.028*\"life\" + 0.027*\"the\" + 0.027*\"from\" + 0.026*\"his\" + 0.023*\"a\"\n0.038*\"and\" + 0.036*\".\" + 0.035*\"i\" + 0.032*\"with\" + 0.030*\"me\" + 0.028*\"life\" + 0.027*\"the\" + 0.027*\"from\" + 0.026*\"his\" + 0.023*\"a\"\n0.038*\"and\" + 0.036*\".\" + 0.035*\"i\" + 0.032*\"with\" + 0.030*\"me\" + 0.028*\"life\" + 0.027*\"the\" + 0.027*\"from\" + 0.026*\"his\" + 0.023*\"a\"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_personal_context(\"i lost my best friend and im so happy\")","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:10:37.839351Z","iopub.execute_input":"2023-08-08T19:10:37.839916Z","iopub.status.idle":"2023-08-08T19:10:37.876720Z","shell.execute_reply.started":"2023-08-08T19:10:37.839874Z","shell.execute_reply":"2023-08-08T19:10:37.875185Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Sentiment Scores: [0.8966]\n\nActual Topics:\n0.115*\"im\" + 0.113*\"lost\" + 0.112*\"my\" + 0.111*\"and\" + 0.111*\"so\" + 0.111*\"i\" + 0.110*\"friend\" + 0.110*\"happy\" + 0.106*\"best\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"the word \"my\" has the highest weight of 0.102 for the extracted topic.\n\nA high weight for the word \"my\" suggests that it is a significant term within the topic identified by the LDA model. This means that the word \"my\" occurs frequently and carries substantial importance within the text when discussing the particular topic associated with that topic index.\n\nIn this case, it indicates that personal ownership or possession, likely related to the topic of loss and enduring emotional impact, plays a prominent role in the text. The word \"my\" may be indicating a personal connection or the speaker's individual perspective in relation to the topic being discussed.","metadata":{}},{"cell_type":"markdown","source":"## 3.Sensory details ","metadata":{}},{"cell_type":"code","source":"import nltk\n\ndef analyze_sensory_details(text):\n    sentences = nltk.sent_tokenize(text)\n\n    sensory_keywords = {\n        'sight': ['see', 'look', 'watch'],\n        'sound': ['hear', 'listen', 'sound'],\n        'smell': ['smell', 'scent', 'aroma'],\n        'taste': ['taste', 'flavor'],\n        'touch': ['feel', 'touch', 'texture']\n    }\n\n    sensory_details = []\n    for sentence in sentences:\n        lower_sentence = sentence.lower()\n        for sense, keywords in sensory_keywords.items():\n            for keyword in keywords:\n                if keyword in lower_sentence:\n                    sensory_details.append({'sense': sense, 'sentence': sentence})\n                    break\n\n    return sensory_details\n","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:19:22.325001Z","iopub.execute_input":"2023-08-08T19:19:22.326097Z","iopub.status.idle":"2023-08-08T19:19:22.334457Z","shell.execute_reply.started":"2023-08-08T19:19:22.326053Z","shell.execute_reply":"2023-08-08T19:19:22.333474Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def test_sensory_details(text):\n    sensory_details = analyze_sensory_details(text)\n    print(\"Sensory Details:\")\n    for detail in sensory_details:\n        print(f\"{detail['sense']}: {detail['sentence']}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:19:26.677377Z","iopub.execute_input":"2023-08-08T19:19:26.678110Z","iopub.status.idle":"2023-08-08T19:19:26.683868Z","shell.execute_reply.started":"2023-08-08T19:19:26.678074Z","shell.execute_reply":"2023-08-08T19:19:26.682612Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_sensory_details(data.iloc[2]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-08T19:21:58.853915Z","iopub.execute_input":"2023-08-08T19:21:58.854375Z","iopub.status.idle":"2023-08-08T19:21:58.861390Z","shell.execute_reply.started":"2023-08-08T19:21:58.854338Z","shell.execute_reply":"2023-08-08T19:21:58.860135Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Sensory Details:\nsight: It would range from learning random science things to make myself look like I'm some sort of a prodigy child to stuff like learning how to play as many sports as possible to look like I was athletic (I wasn't that good at any of them just okay).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4.Phenominal experience ","metadata":{}},{"cell_type":"markdown","source":"using emotional analysis ","metadata":{}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\n\ndef analyze_emotional_tone(text):\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = sia.polarity_scores(text)\n    return sentiment_scores\n\nspeech = \"The loss of my father will forever leave an indelible mark on my heart. But im so happy that he died\"\n\nemotion_scores = analyze_emotional_tone(speech)\nprint(\"Emotion Scores:\", emotion_scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T13:05:41.663302Z","iopub.execute_input":"2023-07-12T13:05:41.664237Z","iopub.status.idle":"2023-07-12T13:05:41.678955Z","shell.execute_reply.started":"2023-07-12T13:05:41.664200Z","shell.execute_reply":"2023-07-12T13:05:41.678097Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Emotion Scores: {'neg': 0.246, 'neu': 0.589, 'pos': 0.164, 'compound': -0.0922}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Truthfulness","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}