{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.chunk import ne_chunk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\nimport spacy\nfrom gensim import corpora, models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-21T13:42:48.941952Z","iopub.execute_input":"2023-08-21T13:42:48.942861Z","iopub.status.idle":"2023-08-21T13:43:07.348786Z","shell.execute_reply.started":"2023-08-21T13:42:48.942793Z","shell.execute_reply":"2023-08-21T13:43:07.347585Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_json('/kaggle/input/stories/data_sensory_details.json')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:00.405123Z","iopub.execute_input":"2023-08-21T13:46:00.405686Z","iopub.status.idle":"2023-08-21T13:46:00.424574Z","shell.execute_reply.started":"2023-08-21T13:46:00.405640Z","shell.execute_reply":"2023-08-21T13:46:00.423654Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":" Criteria for defining a personal event memory by Pillemer ( 1998 ) :  \n*  (a) present a specific event that took place at a particular time and place, rather than a summary event or extended series of events.\n* (b) contain a detailed account of the rememberer's own personal circumstances at the time of the event. \n* (c) evoke sensory images or bodily sensations that contribute to the feeling of \"re-experiencing\" or \"reliving\" the event.\n* (d) link its details and images to a particular moment or moments of phenomenal experience. \n* (e) be believed to be a truthful representation of what actually transpired.","metadata":{}},{"cell_type":"markdown","source":"## 1. Specificity","metadata":{}},{"cell_type":"code","source":"\n# Part-of-Speech (POS) Tagging\ndef pos_tagging(text):\n    return pos_tag(word_tokenize(text))\n\n\n#  Named Entity Recognition (SpaCy)\ndef named_entity_recognition_spacy(text):\n    nlp = spacy.load('en_core_web_sm')\n    doc = nlp(text)\n    named_entities = [ent.text for ent in doc.ents]\n    return named_entities\n\n# Event Extraction\ndef extract_events(text):\n    tokens = word_tokenize(text)\n    tagged = pos_tag(tokens)\n    events = []\n    current_event = []\n    for tag in tagged:\n        if tag[1].startswith('VB'):\n            current_event.append(tag[0])\n        elif current_event:\n            events.append(' '.join(current_event))\n            current_event = []\n    if current_event:\n        events.append(' '.join(current_event))\n    return events\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:04.972351Z","iopub.execute_input":"2023-08-21T13:46:04.972825Z","iopub.status.idle":"2023-08-21T13:46:04.982871Z","shell.execute_reply.started":"2023-08-21T13:46:04.972776Z","shell.execute_reply":"2023-08-21T13:46:04.981699Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(data.iloc[0]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:05.967168Z","iopub.execute_input":"2023-08-21T13:46:05.967604Z","iopub.status.idle":"2023-08-21T13:46:07.425570Z","shell.execute_reply.started":"2023-08-21T13:46:05.967529Z","shell.execute_reply":"2023-08-21T13:46:07.423545Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Story'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'Story'"],"ename":"KeyError","evalue":"'Story'","output_type":"error"}]},{"cell_type":"code","source":"def specificity_spacy(story):\n    sentences = nltk.sent_tokenize(story)\n    tagged_sentences = [pos_tagging(sentence) for sentence in sentences]\n    named_entities = [named_entity_recognition_spacy(sentence) for sentence in sentences]\n    print( \"named entities\", named_entities)\n    events = [extract_events(sentence) for sentence in sentences]\n    print(\"events\", events)\n    total_named_entities = sum(len(ne_list) for ne_list in named_entities)\n    total_events = sum(len(event_list) for event_list in events)\n    total_sentences = len(sentences)\n    \n    threshold = total_sentences // 3\n    \n    # Check if total_named_entities and total_events are greater than the threshold\n    is_specific_story = ( total_named_entities >= threshold ) & ( total_events >= threshold )\n    \n    return is_specific_story","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:19.161696Z","iopub.execute_input":"2023-08-21T13:46:19.162173Z","iopub.status.idle":"2023-08-21T13:46:19.171990Z","shell.execute_reply.started":"2023-08-21T13:46:19.162136Z","shell.execute_reply":"2023-08-21T13:46:19.170498Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Testing the specifity_ne_spacy function :","metadata":{}},{"cell_type":"code","source":"\n\n# Example usage\nstory_text = \"Once upon a time, in a faraway land, there lived a brave knight named Sir Lancelot...\"\nis_specific_story = specificity_spacy(story_text)\nprint(\"Is the story specific?\", is_specific_story)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:23.582938Z","iopub.execute_input":"2023-08-21T13:46:23.583359Z","iopub.status.idle":"2023-08-21T13:46:25.283309Z","shell.execute_reply.started":"2023-08-21T13:46:23.583328Z","shell.execute_reply":"2023-08-21T13:46:25.282005Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"named entities [['Lancelot']]\nevents [['lived', 'named']]\nIs the story specific? True\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Example usage\nstory_text = 'The annual science fair showcased impressive projects from young innovators. Students presented their research findings on various topics. A robot that can solve complex puzzles was a highlight of the event. Researchers discussed cutting-edge advancements in artificial intelligence. The fair concluded with an awards ceremony honoring the top projects.'\nis_specific_story = specificity_spacy(story_text)\nprint(\"Is the story specific?\", is_specific_story)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:29.626023Z","iopub.execute_input":"2023-08-21T13:46:29.627103Z","iopub.status.idle":"2023-08-21T13:46:35.719074Z","shell.execute_reply.started":"2023-08-21T13:46:29.627062Z","shell.execute_reply":"2023-08-21T13:46:35.718017Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"named entities [[], [], [], [], []]\nevents [['showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nIs the story specific? False\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Example usage\nstory_text = 'The annual science called Gitex fair showcased impressive projects from young innovators. Students presented their research findings on various topics. A robot that can solve complex puzzles was a highlight of the event. Researchers discussed cutting-edge advancements in artificial intelligence. The fair concluded with an awards ceremony honoring the top projects.'\nis_specific_story = specificity_spacy(story_text)\nprint(\"Is the story specific?\", is_specific_story)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.724705Z","iopub.status.idle":"2023-08-21T13:43:08.725528Z","shell.execute_reply.started":"2023-08-21T13:43:08.725307Z","shell.execute_reply":"2023-08-21T13:43:08.725330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_specificity_dataframe(data_frame):\n    correct_predictions = 0\n    total_stories = len(data_frame)\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['is_specific']\n        \n        predicted_label = specificity_spacy(story)\n        \n        # Convert boolean to string\n        predicted_label_str = \"yes\" if predicted_label else \"no\"\n        \n        if predicted_label_str == ground_truth_label:\n            correct_predictions += 1\n\n    accuracy = correct_predictions / total_stories\n\n    return accuracy\n\naccuracy = evaluate_specificity_dataframe(data)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:46:38.580373Z","iopub.execute_input":"2023-08-21T13:46:38.581575Z","iopub.status.idle":"2023-08-21T13:47:10.520007Z","shell.execute_reply.started":"2023-08-21T13:46:38.581520Z","shell.execute_reply":"2023-08-21T13:47:10.518741Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"named entities [['Gitex'], [], [], [], []]\nevents [['called', 'showcased'], ['presented'], ['solve', 'was'], ['discussed'], ['concluded', 'honoring']]\nnamed entities [[], [], [], [], []]\nevents [['set'], ['saw', 'turning'], ['flew'], ['descended'], ['was captivating']]\nnamed entities [[], [], [], [], [], [], []]\nevents [['walked'], ['honked', 'shouted'], ['took'], ['gave'], ['cheered'], ['loved'], ['was', 'moving']]\nnamed entities [[], [], [], []]\nevents [['embarked'], ['sought', 'save'], ['encountered', 'forged'], ['were']]\nnamed entities [['midnight'], ['Ali'], [], [], []]\nevents [['struck'], ['crossed'], ['walked'], ['whispered'], ['emerged']]\nAccuracy: 1.00\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_precision(data_frame):\n    true_positives = 0\n    false_positives = 0\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['is_specific']\n\n        predicted_label = specificity_spacy(story)\n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif predicted_label and ground_truth_label == \"no\":\n            false_positives += 1\n\n    precision = true_positives / (true_positives + false_positives)\n    return precision\n\nprecision = evaluate_precision(data)\nprint(f\"Precision: {precision:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.728884Z","iopub.status.idle":"2023-08-21T13:43:08.729293Z","shell.execute_reply.started":"2023-08-21T13:43:08.729095Z","shell.execute_reply":"2023-08-21T13:43:08.729113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_recall(data_frame):\n    true_positives = 0\n    false_negatives = 0\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['is_specific']\n\n        predicted_label = specificity_spacy(story)\n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif not predicted_label and ground_truth_label == \"yes\":\n            false_negatives += 1\n            print(row['story'])\n    recall = true_positives / (true_positives + false_negatives)\n    return recall\n\nrecall = evaluate_recall(data)\nprint(f\"Recall: {recall:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.730679Z","iopub.status.idle":"2023-08-21T13:43:08.731140Z","shell.execute_reply.started":"2023-08-21T13:43:08.730938Z","shell.execute_reply":"2023-08-21T13:43:08.730958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's what recall reflects:\n\nCompleteness: Recall indicates how well your model is capturing all instances of the positive class (in your case, the specific stories). A higher recall means that your model is successfully identifying most of the specific stories present in the dataset.\n\nMissed Positive Cases: A low recall value suggests that your model is missing a significant portion of the positive cases. This could mean that the model is not sensitive enough to detect the specific stories, leading to false negatives.\n\nTrade-off with Precision: Recall is often in conflict with precision. A high recall could lead to more false positives (cases incorrectly classified as positive), as the model may be more inclusive in classifying instances as positive. Balancing recall and precision is important depending on your use case.","metadata":{}},{"cell_type":"markdown","source":"# 2.Personal Context ","metadata":{}},{"cell_type":"code","source":"\n\ndef personal_context(text):\n    # Tokenize text into sentences\n    sentences = nltk.sent_tokenize(text)\n\n    # Sentiment Analysis\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = [sia.polarity_scores(sentence)[\"compound\"] for sentence in sentences]\n\n    # Filter emotional sentences based on sentiment threshold\n    emotional_sentences = [sentence for i, sentence in enumerate(sentences) ]\n    print(emotional_sentences)\n\n    # Initialize the list to store teller's feelings\n    teller_feelings = []\n    \n    # Pronoun and Verbal Analysis\n    for sentence in emotional_sentences:\n        words = nltk.word_tokenize(sentence.lower())\n        person_pronoun = [\"i\", \"me\", \"my\", \"mine\"]\n        verbal_indicators = [\"felt\", \"was\", \"experienced\", \"sensed\",\"loved\",\"hated\"]\n        \n        if any(pronoun in words for pronoun in person_pronoun ) and any(indicator in words for indicator in verbal_indicators):\n            teller_feelings.append(sentence)\n            #print(sentence)\n\n    # Topic Modeling (only if there are teller's feelings)\n    if teller_feelings:\n        tokenized_sentences = [nltk.word_tokenize(sentence.lower()) for sentence in teller_feelings]\n        dictionary = corpora.Dictionary(tokenized_sentences)\n        corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_sentences]\n        lda_model = models.LdaModel(corpus, num_topics=3, id2word=dictionary)\n\n        # Extract most significant topics\n        topics = [lda_model.get_document_topics(doc) for doc in corpus]\n        most_significant_topics = [max(topic, key=lambda x: x[1]) for topic in topics]\n\n        # Get actual topics\n        actual_topics = [lda_model.print_topic(topic[0]) for topic in most_significant_topics]\n    else:\n        actual_topics = []\n\n    # Return emotional sentences, sentiment scores, and actual topics\n    return teller_feelings, sentiment_scores, actual_topics\n\n# Call the function with your input text\nresult = personal_context(\"The mine annual science called Gitex fair showcased impressive projects from young innovators. Students presented their research findings on various topics. A robot that can solve complex puzzles was a highlight of the event. Researchers discussed cutting-edge advancements in artificial intelligence. The fair concluded with an awards ceremony honoring the top projects. i loved it\")\nprint(result)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.732483Z","iopub.status.idle":"2023-08-21T13:43:08.732938Z","shell.execute_reply.started":"2023-08-21T13:43:08.732704Z","shell.execute_reply":"2023-08-21T13:43:08.732723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def has_personal_context(story, sentiment_threshold=0.5):\n    # Run the personal_context function to get the results\n    teller_feelings, sentiment_scores, actual_topics = personal_context(story)\n    \n    # Check if teller_stories is not empty and sentiment score is above threshold\n    if teller_feelings and any(score > sentiment_threshold for score in sentiment_scores):\n        return \"yes\"\n    else:\n        return \"no\"\n\n# Call the has_personal_context function with your input story\nresult = has_personal_context(\"The annual science called Gitex fair showcased impressive projects from young innovators. Students presented their research findings on various topics. A robot that can solve complex puzzles was a highlight of the event. Researchers discussed cutting-edge advancements in artificial intelligence. The fair concluded with an awards ceremony honoring the top projects. i loved it\")\nprint(result)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.734229Z","iopub.status.idle":"2023-08-21T13:43:08.734668Z","shell.execute_reply.started":"2023-08-21T13:43:08.734461Z","shell.execute_reply":"2023-08-21T13:43:08.734480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy_personal_context(data_frame):\n    correct_predictions = 0\n    total_stories = len(data_frame)\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['has_personal_context']\n        \n        predicted_label = has_personal_context(story)\n        \n        \n        if predicted_label == ground_truth_label:\n            correct_predictions += 1\n\n    accuracy = correct_predictions / total_stories\n\n    return accuracy\n\naccuracy = accuracy_personal_context(data)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.737817Z","iopub.status.idle":"2023-08-21T13:43:08.738280Z","shell.execute_reply.started":"2023-08-21T13:43:08.738074Z","shell.execute_reply":"2023-08-21T13:43:08.738094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_personal_context(data_frame):\n    \n    true_positives = 0 \n    false_positives = 0\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['has_personal_context']\n        \n        predicted_label = has_personal_context(story)\n        \n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif predicted_label and ground_truth_label == \"no\":\n            false_positives += 1\n\n    precision = true_positives / (true_positives + false_positives)\n    return precision\n\nprecision = precision_personal_context(data)\nprint(f\"Precision: {precision:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.739492Z","iopub.status.idle":"2023-08-21T13:43:08.739951Z","shell.execute_reply.started":"2023-08-21T13:43:08.739711Z","shell.execute_reply":"2023-08-21T13:43:08.739731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_personal_context(data_frame):\n    true_positives = 0 \n    false_negatives = 0 \n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['has_personal_context']\n        \n        predicted_label = has_personal_context(story)\n        \n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif not predicted_label and ground_truth_label == \"yes\":\n            false_negatives += 1\n\n    recall = true_positives / (true_positives + false_negatives)\n    return recall\n\nrecall = recall_personal_context(data)\nprint(f\"Recall: {recall:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.740911Z","iopub.status.idle":"2023-08-21T13:43:08.741322Z","shell.execute_reply.started":"2023-08-21T13:43:08.741121Z","shell.execute_reply":"2023-08-21T13:43:08.741140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.Sensory details ","metadata":{}},{"cell_type":"code","source":"\n\n# Load the English tokenizer, tagger, parser, NER, and word vectors\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef analyze_sensory_details(text):\n    sentences = nltk.sent_tokenize(text)\n\n    sensory_keywords = {\n        'sight': ['see', 'look', 'watch', 'observe', 'gaze', 'view', 'stare', 'sight'],\n        'sound': ['hear', 'listen', 'sound', 'noise', 'auditory', 'echo', 'sound'],\n        'smell': ['smell', 'scent', 'aroma', 'fragrance', 'odor', 'perfume', 'smell'],\n        'taste': ['taste', 'flavor', 'savor', 'palate', 'tasty', 'delicious', 'taste'],\n        'touch': ['feel', 'touch', 'texture', 'tactile', 'surface', 'contact', 'touch']\n    }\n\n    sensory_details = []\n    for sentence in sentences:\n        doc = nlp(sentence)\n        lemmatized_words = [token.lemma_ for token in doc]\n\n        for sense, keywords in sensory_keywords.items():\n            for keyword in keywords:\n                if keyword in lemmatized_words:\n                    sensory_details.append({'sense': sense, 'sentence': sentence})\n                    break\n\n    return sensory_details\n\n\n\n# Example usage\ntext = \"I saw a beautiful sunset and heard the sound of waves crashing. I don't see well\"\nsensory_results = analyze_sensory_details(text)\nprint(sensory_results)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.742250Z","iopub.status.idle":"2023-08-21T13:43:08.742647Z","shell.execute_reply.started":"2023-08-21T13:43:08.742450Z","shell.execute_reply":"2023-08-21T13:43:08.742468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def has_sensory_details(text):\n    sensory_details = analyze_sensory_details(text)\n    return \"yes\" if sensory_details else \"no\"\n\ntext = \"The sun sets over the mountains, casting a warm orange glow. Birds sing in the trees, and the scent of blooming flowers fills the air.\"\nresult = has_sensory_details(text)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.744146Z","iopub.status.idle":"2023-08-21T13:43:08.744546Z","shell.execute_reply.started":"2023-08-21T13:43:08.744352Z","shell.execute_reply":"2023-08-21T13:43:08.744371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"has_sensory_details(data.iloc[2]['Story'])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.745730Z","iopub.status.idle":"2023-08-21T13:43:08.746172Z","shell.execute_reply.started":"2023-08-21T13:43:08.745976Z","shell.execute_reply":"2023-08-21T13:43:08.745995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy_sensory_details(data_frame):\n    correct_predictions = 0\n    total_stories = len(data_frame)\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['has_sensory_details']\n        \n        predicted_label = has_personal_context(story)\n        \n        \n        if predicted_label == ground_truth_label:\n            correct_predictions += 1\n\n    accuracy = correct_predictions / total_stories\n\n    return accuracy\n\naccuracy = accuracy_sensory_details(data)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.747166Z","iopub.status.idle":"2023-08-21T13:43:08.747563Z","shell.execute_reply.started":"2023-08-21T13:43:08.747372Z","shell.execute_reply":"2023-08-21T13:43:08.747390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_sensory_details(data_frame):\n    \n    true_positives = 0 \n    false_positives = 0\n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['has_sensory_details']\n        \n        predicted_label = has_sensory_details(story)\n        \n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif predicted_label and ground_truth_label == \"no\":\n            false_positives += 1\n\n    precision = true_positives / (true_positives + false_positives)\n    return precision\n\nprecision = precision_sensory_details(data)\nprint(f\"Precision: {precision:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.749102Z","iopub.status.idle":"2023-08-21T13:43:08.749505Z","shell.execute_reply.started":"2023-08-21T13:43:08.749308Z","shell.execute_reply":"2023-08-21T13:43:08.749327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_sensory_details(data_frame):\n    true_positives = 0 \n    false_negatives = 0 \n\n    for index, row in data_frame.iterrows():\n        story = row['story']\n        ground_truth_label = row['has_sensory_details']\n        \n        predicted_label = has_personal_context(story)\n        \n        \n        if predicted_label and ground_truth_label == \"yes\":\n            true_positives += 1\n        elif not predicted_label and ground_truth_label == \"yes\":\n            false_negatives += 1\n\n    recall = true_positives / (true_positives + false_negatives)\n    return recall\n\nrecall = recall_sensory_details(data)\nprint(f\"Recall: {recall:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-21T13:43:08.750608Z","iopub.status.idle":"2023-08-21T13:43:08.751029Z","shell.execute_reply.started":"2023-08-21T13:43:08.750792Z","shell.execute_reply":"2023-08-21T13:43:08.750834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Causal Coherence ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}